{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Intermediate Prompting: Reasoning & Examples\n",
                "\n",
                "This notebook demonstrates **Few-Shot Prompting** and **Chain-of-Thought (CoT)**, two powerful techniques for handling complex tasks."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def mock_llm_reasoning(prompt):\n",
                "    # Simulating simple reasoning\n",
                "    if \"Sentiment:\" in prompt and \"waste of money\" in prompt:\n",
                "        return \"Sentiment: Negative\"\n",
                "    elif \"step by step\" in prompt.lower():\n",
                "        return \"Step 1: 4 notebooks * $4 = $16. Step 2: $26 total - $16 = $10. Step 3: $10 / $2 per pen = 5 pens. Answer: 5\"\n",
                "    else:\n",
                "        # Without CoT, models might guess\n",
                "        return \"Answer: 5\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Few-Shot Prompting\n",
                "\n",
                "Giving examples helps the model understand the pattern and desired format."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "few_shot_prompt = \"\"\"\n",
                "Classify the sentiment of the reviews.\n",
                "\n",
                "Review: \"Loved it!\"\n",
                "Sentiment: Positive\n",
                "\n",
                "Review: \"It's okay.\"\n",
                "Sentiment: Neutral\n",
                "\n",
                "Review: \"Don't buy this, waste of money.\"\n",
                "\"\"\"\n",
                "\n",
                "print(\"--- Few-Shot Classification ---\")\n",
                "print(mock_llm_reasoning(few_shot_prompt))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Chain-of-Thought (CoT)\n",
                "\n",
                "Asking the model to think \"step-by-step\" drastically improves math and logic performance."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "problem = \"A store sells notebooks for $4 and pens for $2. Maria spent $26 and bought 4 notebooks. How many pens did she buy?\"\n",
                "\n",
                "# Zero-Shot CoT\n",
                "cot_prompt = f\"{problem}\\nLet's think step by step.\"\n",
                "\n",
                "print(\"--- Chain of Thought ---\")\n",
                "print(mock_llm_reasoning(cot_prompt))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}