[Home](https://natnew.github.io/Awesome-Prompt-Engineering/)

## Articles

Curated reading on prompt engineering, context engineering, and building with LLMs. Organized by topic for practitioners at all levels.

> **Contribute:** Found an essential article? Submit a PR or open an issue.

---

### Contents

- [Context Engineering & Prompting](#context-engineering--prompting)
- [Building with LLMs](#building-with-llms)
- [Agents & Orchestration](#agents--orchestration)
- [RAG & Knowledge Systems](#rag--knowledge-systems)
- [Evaluation & Testing](#evaluation--testing)
- [Safety & Security](#safety--security)
- [Production & Operations](#production--operations)
- [Research & Theory](#research--theory)

---

## Context Engineering & Prompting

*The craft of communicating effectively with LLMs.*

| Article | Author/Source | Why Read It |
|:--------|:--------------|:------------|
| [Prompt Engineering](https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/) | Lilian Weng | Comprehensive technical overview of prompting techniques |
| [What We Learned from a Year of Building with LLMs (Part I)](https://www.oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-i/) | O'Reilly | Production lessons from practitioners |
| [What We Learned from a Year of Building with LLMs (Part II)](https://www.oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-ii/) | O'Reilly | Operations and organizational insights |
| [Prompting Fundamentals](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview) | Anthropic | Official Claude prompting best practices |
| [The Art of Prompt Design](https://platform.openai.com/docs/guides/prompt-engineering) | OpenAI | Official GPT prompting guide |
| <!-- PLACEHOLDER --> | <!-- SOURCE --> | <!-- DESCRIPTION --> |

---

## Building with LLMs

*Architecture patterns and system design for LLM applications.*

| Article | Author/Source | Why Read It |
|:--------|:--------------|:------------|
| [Patterns for Building LLM-based Systems & Products](https://eugeneyan.com/writing/llm-patterns/) | Eugene Yan | Essential architectural patterns |
| [The Shift from Models to Compound AI Systems](https://bair.berkeley.edu/blog/2024/02/18/compound-ai-systems/) | Berkeley AI Research | Why pipelines beat single models |
| [Building LLM Applications for Production](https://huyenchip.com/2023/04/11/llm-engineering.html) | Chip Huyen | Production engineering considerations |
| [LLM App Stack](https://github.com/a]16z-infra/llm-app-stack) | a]16z | Reference architecture for LLM apps |
| <!-- PLACEHOLDER --> | <!-- SOURCE --> | <!-- DESCRIPTION --> |

---

## Agents & Orchestration

*Building autonomous AI systems that reason and act.*

| Article | Author/Source | Why Read It |
|:--------|:--------------|:------------|
| [Building Effective Agents](https://www.anthropic.com/research/building-effective-agents) | Anthropic | Official guide to agent development |
| [LLM Powered Autonomous Agents](https://lilianweng.github.io/posts/2023-06-23-agent/) | Lilian Weng | Deep dive into agent architectures |
| [Cognitive Architectures for Language Agents](https://arxiv.org/abs/2309.02427) | CoALA Paper | Academic framework for agent design |
| [The Agent Reasoning Loop](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/) | LangChain | ReAct, Plan-and-Execute, and more |
| <!-- PLACEHOLDER --> | <!-- SOURCE --> | <!-- DESCRIPTION --> |

---

## RAG & Knowledge Systems

*Grounding LLMs with external knowledge.*

| Article | Author/Source | Why Read It |
|:--------|:--------------|:------------|
| [A Survey on RAG for LLMs](https://arxiv.org/abs/2312.10997) | arXiv | Comprehensive academic overview |
| [Chunking Strategies for LLM Applications](https://www.pinecone.io/learn/chunking-strategies/) | Pinecone | Practical document splitting guide |
| [Advanced RAG Techniques](https://docs.llamaindex.ai/en/stable/optimizing/production_rag/) | LlamaIndex | Production RAG optimization |
| [Retrieval Augmented Generation: A Practical Guide](https://docs.cohere.com/docs/retrieval-augmented-generation-rag) | Cohere | End-to-end RAG implementation |
| <!-- PLACEHOLDER --> | <!-- SOURCE --> | <!-- DESCRIPTION --> |

---

## Evaluation & Testing

*Measuring what matters in LLM systems.*

| Article | Author/Source | Why Read It |
|:--------|:--------------|:------------|
| [Your AI Product Needs Evals](https://hamel.dev/blog/posts/evals/) | Hamel Husain | Why and how to evaluate LLM apps |
| [How to Evaluate LLMs: A Complete Metric Framework](https://www.oreilly.com/radar/how-to-evaluate-llms-a-complete-metric-framework/) | O'Reilly | Comprehensive evaluation metrics |
| [LLM-as-Judge](https://arxiv.org/abs/2306.05685) | arXiv | Using LLMs to evaluate LLMs |
| [A Practical Guide to LLM Evaluation](https://www.confident-ai.com/blog/llm-evaluation-metrics-everything-you-need-for-llm-evaluation) | Confident AI | Metrics and methodologies |
| <!-- PLACEHOLDER --> | <!-- SOURCE --> | <!-- DESCRIPTION --> |

---

## Safety & Security

*Building robust, secure, and aligned LLM systems.*

| Article | Author/Source | Why Read It |
|:--------|:--------------|:------------|
| [Prompt Injection: What's the Worst That Can Happen?](https://simonwillison.net/2023/Apr/14/worst-that-can-happen/) | Simon Willison | Understanding prompt injection risks |
| [OWASP Top 10 for LLM Applications](https://owasp.org/www-project-top-10-for-large-language-model-applications/) | OWASP | Security risks and mitigations |
| [Constitutional AI](https://www.anthropic.com/research/constitutional-ai-harmlessness-from-ai-feedback) | Anthropic | Self-correction against principles |
| [Red Teaming Language Models](https://arxiv.org/abs/2202.03286) | arXiv | Adversarial testing methods |
| [Many-Shot Jailbreaking](https://www.anthropic.com/research/many-shot-jailbreaking) | Anthropic | Long-context vulnerabilities |
| <!-- PLACEHOLDER --> | <!-- SOURCE --> | <!-- DESCRIPTION --> |

---

## Production & Operations

*Running LLM systems at scale.*

| Article | Author/Source | Why Read It |
|:--------|:--------------|:------------|
| [LLMOps: Everything You Need to Know](https://www.lakera.ai/blog/llmops) | Lakera | Operations overview |
| [Monitoring LLMs in Production](https://www.arize.com/blog/llm-monitoring/) | Arize AI | Observability practices |
| [Cost Optimization for LLM Applications](https://www.helicone.ai/blog/llm-cost-optimization) | Helicone | Managing API costs |
| [Caching Strategies for LLM Apps](https://www.gptcache.io/) | GPTCache | Reducing latency and cost |
| <!-- PLACEHOLDER --> | <!-- SOURCE --> | <!-- DESCRIPTION --> |

---

## Research & Theory

*Understanding the foundations.*

| Article | Author/Source | Why Read It |
|:--------|:--------------|:------------|
| [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/) | Jay Alammar | Visual guide to transformer architecture |
| [Attention Is All You Need (Annotated)](https://nlp.seas.harvard.edu/annotated-transformer/) | Harvard NLP | The foundational paper, explained |
| [Scaling Laws for Neural Language Models](https://arxiv.org/abs/2001.08361) | OpenAI | Why scale matters |
| [A Survey of Large Language Models](https://arxiv.org/abs/2303.18223) | arXiv | Comprehensive LLM overview |
| [Towards Monosemanticity](https://www.anthropic.com/research/towards-monosemanticity-decomposing-language-models-with-dictionary-learning) | Anthropic | Understanding what's inside LLMs |
| <!-- PLACEHOLDER --> | <!-- SOURCE --> | <!-- DESCRIPTION --> |

---

## Contributing

To suggest an article:
1. Open an issue with the article URL and a brief description
2. Or submit a PR adding it to the appropriate section

**Criteria for inclusion:**
- Answers a real question practitioners have
- From a credible source (researcher, practitioner, or organization)
- Provides actionable insights, not just overview
- Stands the test of time (not purely news)

---

### Notes

Feedback and suggestions are welcome!

*Last updated: January 2026*