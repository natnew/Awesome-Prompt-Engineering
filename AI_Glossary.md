---
layout: default
title: AI Glossary
description: Definitions of key AI and prompt engineering terms.
nav_order: 14
---

[Home](https://natnew.github.io/Awesome-Prompt-Engineering/)

# AI Glossary

A comprehensive collection of terms and definitions related to the field of Artificial Intelligence, Machine Learning, and Prompt Engineering.

---

**Active Learning** | A machine learning approach that involves the model selecting the most informative data samples for labeling, improving its accuracy while reducing labeling costs. <br><br>
**Adversarial Examples** | Inputs that are intentionally designed to deceive machine learning models, highlighting potential vulnerabilities and weaknesses in the system. <br><br>
**Adversarial Machine Learning** | A technique that involves training machine learning models to detect and defend against attacks from malicious actors, such as adversarial examples and poisoned data. <br><br>
**Adversarial Networks** | A type of neural network that involves two or more networks working against each other to improve performance or generate new data, such as adversarial autoencoders. <br><br>
**AI Agent** | An AI system that can autonomously plan, reason, and take actions to accomplish goals, often using tools and interacting with external environments. <br><br>
**AI Alignment** | The challenge of ensuring AI systems behave in accordance with human values, intentions, and goals. <br><br>
**AI Ethics** | The study of moral and ethical issues arising from the use of artificial intelligence, including transparency, accountability, bias, and privacy. <br><br>
**Algorithm** | A set of instructions or rules that a machine follows to perform a task. <br><br>
**Anomaly Detection** | A type of unsupervised learning that involves identifying rare or unusual events or patterns in data. <br><br>
**API** | Application Programming Interface is a set of protocols, routines, and tools for building software and applications. <br><br>
**Array** | A collection of values or elements of the same data type that are stored in a contiguous memory location in computer programming. <br><br>
**Artificial Intelligence (AI)** | The ability of machines to perform tasks that typically require human intelligence, such as visual perception, speech recognition, decision-making, and natural language processing. <br><br>
**Attention Mechanism** | A technique used in neural networks to selectively focus on different parts of the input data based on their relevance to the task at hand. <br><br>
**Augmented Intelligence** | A human-centric approach to AI that focuses on using machine intelligence to augment human capabilities, rather than replace them. <br><br>
**Autoencoder** | A type of neural network used for unsupervised learning, which learns to compress and decompress data, enabling feature extraction and dimensionality reduction. <br><br>
**AutoML** | Automated Machine Learning refers to the use of automated tools and techniques to streamline the process of building and training machine learning models. <br><br>
**Autonomous Systems** | Systems that can operate independently without human intervention, such as self-driving cars and unmanned aerial vehicles. <br><br>
**Backpropagation** | A method for training neural networks by calculating the error between predicted and actual output and adjusting the weights of the network backwards through the layers. <br><br>
**Bagging** | A technique used to improve the stability and accuracy of a machine learning model by training multiple models on randomly sampled subsets of the training data and combining their predictions. <br><br>
**Batch Normalization** | A technique used to improve the training of deep neural networks by normalizing the inputs of each layer to have zero mean and unit variance over each mini-batch. <br><br>
**Bayesian Optimization** | A method for optimizing machine learning models by choosing the best hyperparameters, such as learning rate and regularization, based on the results of previous iterations. <br><br>
**Bias-Variance Tradeoff** | The balance between model complexity and generalization performance in machine learning, where increasing model complexity may reduce bias but increase variance. <br><br>
**Big Data** | Extremely large datasets that can be analyzed to reveal patterns, trends, and insights that can inform decision-making. <br><br>
**Capsule Network** | A type of neural network architecture that uses groups of neurons called "capsules" to represent visual concepts and relationships between them, and has shown promise in improving image recognition and processing. <br><br>
**Causal Inference** | The process of determining the causal relationships between variables, such as identifying the impact of a specific policy or intervention on a target outcome. <br><br>
**Chain-of-Thought (CoT)** | A prompting technique that encourages language models to break down complex problems into intermediate reasoning steps before providing a final answer. <br><br>
**Chatbot** | An AI-based application that uses natural language processing to interact with humans through chat interfaces, typically on messaging platforms or websites. <br><br>
**Chunking** | The process of splitting documents into smaller segments for embedding and retrieval in RAG systems. <br><br>
**Class** | A blueprint or template for creating objects in object-oriented programming that defines data and behavior. <br><br>
**Clustering** | A type of unsupervised learning that involves grouping similar data points together based on their features or attributes. <br><br>
**Cognitive Automation** | The use of AI and automation to perform tasks that require human-level cognitive abilities, such as natural language understanding and problem-solving. <br><br>
**Compiler** | A program that translates source code written in one programming language into another programming language or machine code. <br><br>
**Computer Vision** | A subset of AI that focuses on enabling machines to interpret and understand visual information from the world around them, including images and videos. <br><br>
**Constitutional AI** | An AI training approach that uses a set of principles to guide model behavior through self-critique and revision. <br><br>
**Context Engineering** | The practice of architecting the complete information environment that shapes model behavior, including system prompts, conversation history, retrieved knowledge, and tool definitions. <br><br>
**Context Window** | The maximum amount of text (measured in tokens) that a language model can process in a single input, determining how much information it can consider at once. <br><br>
**Continual Learning** | A machine learning approach that involves learning from a continuous stream of data, enabling models to adapt and improve over time. <br><br>
**Convolutional Neural Networks (CNNs)** | A type of neural network commonly used for computer vision tasks, such as image recognition and object detection. <br><br>
**Cross-Validation** | A technique for assessing the performance of machine learning models by testing them on multiple subsets of the data. <br><br>
**Data Governance** | A set of processes and policies that ensure the proper management, protection, and utilization of an organization's data assets. <br><br>
**Data Imputation** | The process of filling in missing or incomplete data with estimated values or imputed data. <br><br>
**Data Integration** | The process of combining data from multiple sources into a single, unified view. <br><br>
**Data Lake** | A storage repository that allows organizations to store large amounts of structured, semi-structured, and unstructured data at scale. <br><br>
**Data Mining** | The process of discovering patterns and insights from large amounts of data, typically using statistical and computational methods. <br><br>
**Data Pipeline** | A series of automated processes that extract, transform, and load data from various sources into a target system. <br><br>
**Data Profiling** | The process of analyzing and assessing the quality, completeness, and consistency of a dataset. <br><br>
**Data Quality** | The accuracy, completeness, consistency, and timeliness of data. <br><br>
**Data Stewardship** | The ongoing management and maintenance of data to ensure its accuracy, completeness, and consistency. <br><br>
**Data Wrangling** | The process of cleaning, transforming, and preparing raw data for analysis or modeling. <br><br>
**Debugging** | The process of identifying and fixing errors or defects in computer programs. <br><br>
**Decision Trees** | A machine learning technique that involves building a tree-like model of decisions based on features and outcomes, often used for classification and regression tasks. <br><br>
**Deep Learning** | A subset of ML that uses neural networks to analyze large amounts of data, enabling machines to recognize patterns and make more accurate predictions. <br><br>
**Deep Reinforcement Learning** | A type of machine learning that combines deep learning and reinforcement learning, enabling models to learn from trial and error in complex environments. <br><br>
**Differentiable Programming** | The use of automatic differentiation to enable machine learning models to be used as building blocks for other models, enabling faster and more efficient model design. <br><br>
**Diffusion Model** | A generative model that learns to create data by gradually removing noise from random inputs, widely used for image generation. <br><br>
**Dimensionality Reduction** | The process of reducing the number of features or variables in a dataset, often used to simplify analysis or visualization, or to address the curse of dimensionality. <br><br>
**Edge AI** | The use of artificial intelligence algorithms and models on edge devices, such as smartphones, IoT devices, and drones, to enable real-time decision-making and reduce latency. <br><br>
**Embedding** | A numerical vector representation of data (text, images, etc.) that captures semantic meaning, enabling similarity comparisons and search. <br><br>
**Emergent Behavior** | Capabilities that arise in large AI models that were not explicitly programmed or present in smaller versions of the same architecture. <br><br>
**Ensemble Learning** | A technique for combining multiple machine learning models to improve overall performance, often using methods such as bagging, boosting, or stacking. <br><br>
**Evolutionary Algorithms** | A family of optimization algorithms that are inspired by biological evolution, such as genetic algorithms and evolution strategies. <br><br>
**Expert System** | A computer program that emulates the decision-making abilities of a human expert in a particular domain. <br><br>
**Explainability Gap** | The difference between the level of understanding humans have of a machine learning model and the actual decision-making process of the model, which can lead to mistrust and ethical concerns. <br><br>
**Explainable AI (XAI)** | An approach to AI that aims to make machine learning models more transparent and interpretable, enabling humans to understand how decisions are made and identify potential biases. <br><br>
**Feature Extraction** | The process of selecting or transforming input data into a form that is suitable for machine learning algorithms. <br><br>
**Federated Learning** | A machine learning technique that enables multiple devices or servers to collaboratively train a model without sharing raw data with each other. <br><br>
**Few-Shot Learning** | A type of machine learning that involves training models to learn from a small number of examples, enabling faster and more efficient learning. <br><br>
**Fine-Tuning** | The process of further training a pre-trained model on task-specific data to improve its performance on particular applications. <br><br>
**Foundation Model** | A large AI model trained on broad data that can be adapted to a wide range of downstream tasks through fine-tuning or prompting. <br><br>
**Framework** | A set of software components that provides a foundation for developing software applications in a specific programming language or environment. <br><br>
**Function** | A reusable block of code that performs a specific task and can be called by other parts of the program. <br><br>
**Generative Adversarial Networks (GANs)** | A type of deep learning model that involves two neural networks working together to generate new data, such as images or audio, that is similar to a given dataset. <br><br>
**GPT (Generative Pre-trained Transformer)** | A family of large language models created by OpenAI, capable of generating natural language text, translating languages, and answering questions. <br><br>
**Gradient Boosting** | A machine learning technique that involves combining multiple weak models (usually decision trees) into a strong ensemble model, often used for regression and classification tasks. <br><br>
**Gradient Descent** | A popular optimization algorithm used in machine learning to adjust the weights and biases of neural networks and other models. <br><br>
**Grounding** | Techniques that anchor AI outputs to verified sources or real-world data to reduce hallucinations and improve factual accuracy. <br><br>
**Guardrails** | Safety mechanisms and constraints implemented to prevent AI models from generating harmful, biased, or inappropriate outputs. <br><br>
**Hallucination** | When an AI model generates plausible-sounding but factually incorrect or fabricated information. <br><br>
**Human-in-the-Loop (HITL)** | An approach to AI that involves human oversight and intervention to ensure that machine learning models are accurate, ethical, and aligned with human values. <br><br>
**Hyperautomation** | A digital transformation strategy that combines AI, machine learning, and other technologies to automate and optimize business processes. <br><br>
**Hyperparameter Tuning** | The process of adjusting the settings or parameters of a machine learning algorithm to optimize its performance on a given task or dataset. <br><br>
**IDE (Integrated Development Environment)** | A software application that provides comprehensive facilities to computer programmers for software development. <br><br>
**In-Context Learning** | The ability of language models to learn and adapt to new tasks from examples provided within the prompt, without updating model weights. <br><br>
**Inference** | The process of running a trained model to generate predictions or outputs from new input data. <br><br>
**Jailbreaking** | Techniques used to bypass the safety guidelines and content restrictions of AI models to elicit prohibited outputs. <br><br>
**Knowledge Graphs** | A type of graph database that stores and represents knowledge in a structured format, enabling AI systems to reason and make inferences based on the data. <br><br>
**Large Language Model (LLM)** | A neural network trained on massive text datasets that can understand and generate human-like text, typically with billions of parameters. <br><br>
**Latent Space** | A compressed, lower-dimensional representation of data learned by generative models, where similar concepts are positioned nearby. <br><br>
**Loop** | A control structure that repeats a block of code until a certain condition is met. <br><br>
**LoRA (Low-Rank Adaptation)** | An efficient fine-tuning technique that reduces computational requirements by training only small adapter layers rather than all model parameters. <br><br>
**Machine Learning (ML)** | A subset of AI that uses statistical models and algorithms to enable machines to learn from data and make predictions or decisions without being explicitly programmed. <br><br>
**Meta-Learning** | A machine learning approach that involves learning how to learn, enabling models to generalize to new tasks and data more effectively. <br><br>
**Metadata** | Data that describes other data, including information about data sources, data lineage, data quality, and data relationships. <br><br>
**Mixture of Experts (MoE)** | A neural network architecture that uses multiple specialized sub-networks (experts) and a routing mechanism to efficiently scale model capacity. <br><br>
**Model Context Protocol (MCP)** | An open protocol that standardizes how AI applications connect to external data sources and tools. <br><br>
**Model Evaluation (Evals)** | The systematic assessment of AI model performance using benchmarks, metrics, and human judgment to measure quality and safety. <br><br>
**Model Selection** | The process of choosing the most appropriate machine learning model for a given task or dataset, based on factors such as accuracy, complexity, and interpretability. <br><br>
**Module** | A self-contained unit of code that can be reused and imported into other programs in computer programming. <br><br>
**Multi-Agent System** | An AI architecture where multiple specialized agents collaborate, communicate, and coordinate to solve complex problems. <br><br>
**Multi-Modal AI** | An AI system that can understand and process multiple forms of data, such as text, images, and audio, to make more accurate predictions or decisions. <br><br>
**Multi-Modal Learning** | A machine learning technique that involves processing multiple types of data simultaneously, such as text, images, and audio. <br><br>
**Natural Language Generation (NLG)** | A type of AI technology that enables machines to produce human-like language and generate written or spoken content. <br><br>
**Natural Language Processing (NLP)** | The ability of machines to understand, interpret, and generate human language. <br><br>
**Neural Network** | A type of machine learning model inspired by the structure of the human brain, consisting of interconnected nodes that process and transmit information. <br><br>
**Neuromorphic Computing** | A type of computing that is inspired by the structure and function of biological neural networks, enabling the creation of more efficient and scalable AI systems. <br><br>
**Object** | An instance of a class in object-oriented programming that encapsulates data and behavior. <br><br>
**One-Shot Learning** | A type of machine learning that involves learning from a single or few examples, often used to address the data scarcity problem. <br><br>
**Orchestration** | The coordination and management of multiple AI agents, tools, or model calls to accomplish complex multi-step tasks. <br><br>
**Overfitting** | When a machine learning model is overly complex and fits the training data too closely, leading to poor performance on new, unseen data. <br><br>
**Pointer** | A variable that holds the memory address of another variable in computer programming. <br><br>
**Predictive Analytics** | The use of statistical models and machine learning algorithms to make predictions or forecasts about future events based on historical data. <br><br>
**Principal Component Analysis (PCA)** | A dimensionality reduction technique that involves transforming a dataset into a lower-dimensional space while preserving the most important information. <br><br>
**Prompt Engineering** | The process of designing, refining, and optimizing natural language prompts to elicit desired responses from language models. <br><br>
**Prompt Injection** | A security vulnerability where malicious inputs manipulate a language model into ignoring its instructions or performing unintended actions. <br><br>
**Prompt Tuning** | The process of adjusting and fine-tuning prompts to improve the performance of language models on specific tasks. <br><br>
**Quantization** | A model compression technique that reduces the precision of model weights to decrease memory usage and increase inference speed. <br><br>
**Quantum Machine Intelligence** | The integration of quantum computing and machine learning, enabling the creation of more efficient and accurate AI systems. <br><br>
**Quantum Machine Learning** | The use of quantum computing to accelerate machine learning tasks, such as optimization and pattern recognition, enabling faster and more efficient learning. <br><br>
**Quantum Neural Networks (QNNs)** | A type of neural network designed to run on quantum computing architectures, enabling faster and more efficient processing of complex data. <br><br>
**Random Forest** | A machine learning technique that involves constructing multiple decision trees and combining their predictions to improve the accuracy and stability of a model. <br><br>
**Red Teaming** | A systematic approach to testing AI systems by simulating adversarial attacks to identify vulnerabilities and failure modes. <br><br>
**Regularization** | A technique for preventing overfitting in machine learning by adding a penalty term to the model that encourages simpler, more generalizable solutions. <br><br>
**Reinforcement Learning** | A type of machine learning in which an agent learns to interact with an environment by performing actions and receiving rewards or punishments based on those actions. <br><br>
**Responsible AI** | The development and deployment of AI systems that are transparent, accountable, and designed to minimize negative impacts on society and the environment. <br><br>
**Retrieval-Augmented Generation (RAG)** | A technique that enhances language model outputs by retrieving relevant information from external knowledge sources and including it in the context. <br><br>
**RLHF (Reinforcement Learning from Human Feedback)** | A training technique that uses human preferences to guide model behavior, helping align outputs with human values and expectations. <br><br>
**Robotics** | The field of engineering that involves designing and building robots that can perform a variety of tasks, ranging from manufacturing and assembly to exploration and rescue operations. <br><br>
**Self-Supervised Learning** | A machine learning approach that enables models to learn from unlabeled data, reducing the need for human-labeled datasets. <br><br>
**Semantic Search** | A search technique that uses embeddings to find results based on meaning and intent rather than exact keyword matches. <br><br>
**Speech Recognition** | The ability of machines to recognize and transcribe spoken language into text. <br><br>
**Supervised Learning** | A type of machine learning where the algorithm learns from labeled training data, and makes predictions or decisions based on that learning. <br><br>
**Swarm Intelligence** | A collective intelligence approach inspired by social behavior in insects and animals, used to optimize decision-making in complex systems. <br><br>
**Synthetic Biology** | The design and engineering of biological systems using synthetic DNA, enabling the creation of new organisms and materials with specific functions. <br><br>
**Synthetic Data** | Artificially generated data that is designed to mimic real-world data, used for training and testing machine learning models while preserving data privacy. <br><br>
**Synthetic Media** | AI-generated media, such as images, videos, and audio, that can be used for entertainment, marketing, or other applications. <br><br>
**System Prompt** | Instructions provided to a language model that define its behavior, persona, capabilities, and constraints across an entire conversation. <br><br>
**Temperature** | A parameter that controls the randomness of model outputs, where higher values produce more creative responses and lower values produce more deterministic ones. <br><br>
**Time Series Analysis** | A type of analysis that involves modeling and forecasting data that is indexed by time, such as stock prices, weather patterns, or website traffic. <br><br>
**Token** | The basic unit of text processed by language models, which can be a word, subword, or character depending on the tokenization method. <br><br>
**Tool Use / Function Calling** | The capability of language models to invoke external tools, APIs, or functions to extend their abilities beyond text generation. <br><br>
**Transfer Learning** | A machine learning approach that involves reusing pre-trained models and transferring knowledge to new domains or tasks, enabling faster and more efficient learning. <br><br>
**Transformer** | A type of neural network architecture that uses attention mechanisms to process input sequences, and has achieved state-of-the-art results in natural language processing. <br><br>
**Underfitting** | When a machine learning model is too simple and fails to capture the underlying patterns in the data, leading to poor performance on both training and new data. <br><br>
**Unsupervised Learning** | A type of machine learning in which the model is trained on unlabeled data and must identify patterns and structures on its own. <br><br>
**Variable** | A named container that holds a value or reference to a value in computer programming. <br><br>
**Variational Autoencoder (VAE)** | An extension of the autoencoder architecture that learns a probability distribution over the compressed representations of input data, allowing for the generation of new, similar data points. <br><br>
**Vector Database** | A specialized database designed to store, index, and query high-dimensional embedding vectors for fast similarity search. <br><br>
**Zero-Shot Learning** | The ability of a model to perform a task without any task-specific examples, relying solely on instructions and pre-trained knowledge. <br><br>

---

[Download CSV](https://github.com/natnew/Awesome-Prompt-Engineering/blob/main/AI%20Glossary.csv)