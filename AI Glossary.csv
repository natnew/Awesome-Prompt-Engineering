Term,Definition
Active Learning,"A machine learning approach that involves the model selecting the most informative data samples for labeling, improving its accuracy while reducing labeling costs."
Adversarial Examples,"Inputs that are intentionally designed to deceive machine learning models, highlighting potential vulnerabilities and weaknesses in the system."
Adversarial Machine Learning,"A technique that involves training machine learning models to detect and defend against attacks from malicious actors, such as adversarial examples and poisoned data."
Adversarial Networks,"A type of neural network that involves two or more networks working against each other to improve performance or generate new data, such as adversarial autoencoders."
AI Agent,"An AI system that can autonomously plan, reason, and take actions to accomplish goals, often using tools and interacting with external environments."
AI Alignment,"The challenge of ensuring AI systems behave in accordance with human values, intentions, and goals."
AI Ethics,"The study of moral and ethical issues arising from the use of artificial intelligence, including transparency, accountability, bias, and privacy."
Algorithm,A set of instructions or rules that a machine follows to perform a task.
Anomaly Detection,A type of unsupervised learning that involves identifying rare or unusual events or patterns in data.
API,"Application Programming Interface is a set of protocols, routines, and tools for building software and applications."
Array,A collection of values or elements of the same data type that are stored in a contiguous memory location in computer programming.
Artificial Intelligence (AI),"The ability of machines to perform tasks that typically require human intelligence, such as visual perception, speech recognition, decision-making, and natural language processing."
Attention Mechanism,A technique used in neural networks to selectively focus on different parts of the input data based on their relevance to the task at hand.
Augmented Intelligence,"A human-centric approach to AI that focuses on using machine intelligence to augment human capabilities, rather than replace them."
Autoencoder,"A type of neural network used for unsupervised learning, which learns to compress and decompress data, enabling feature extraction and dimensionality reduction."
AutoML,Automated Machine Learning refers to the use of automated tools and techniques to streamline the process of building and training machine learning models.
Autonomous Systems,"Systems that can operate independently without human intervention, such as self-driving cars and unmanned aerial vehicles."
Backpropagation,A method for training neural networks by calculating the error between predicted and actual output and adjusting the weights of the network backwards through the layers.
Bagging,A technique used to improve the stability and accuracy of a machine learning model by training multiple models on randomly sampled subsets of the training data and combining their predictions.
Batch Normalization,A technique used to improve the training of deep neural networks by normalizing the inputs of each layer to have zero mean and unit variance over each mini-batch.
Bayesian Optimization,"A method for optimizing machine learning models by choosing the best hyperparameters, such as learning rate and regularization, based on the results of previous iterations."
Bias-Variance Tradeoff,"The balance between model complexity and generalization performance in machine learning, where increasing model complexity may reduce bias but increase variance."
Big Data,"Extremely large datasets that can be analyzed to reveal patterns, trends, and insights that can inform decision-making."
Capsule Network,"A type of neural network architecture that uses groups of neurons called ""capsules"" to represent visual concepts and relationships between them, and has shown promise in improving image recognition and processing."
Causal Inference,"The process of determining the causal relationships between variables, such as identifying the impact of a specific policy or intervention on a target outcome."
Chain-of-Thought (CoT),A prompting technique that encourages language models to break down complex problems into intermediate reasoning steps before providing a final answer.
Chatbot,"An AI-based application that uses natural language processing to interact with humans through chat interfaces, typically on messaging platforms or websites."
Chunking,The process of splitting documents into smaller segments for embedding and retrieval in RAG systems.
Class,A blueprint or template for creating objects in object-oriented programming that defines data and behavior.
Clustering,A type of unsupervised learning that involves grouping similar data points together based on their features or attributes.
Cognitive Automation,"The use of AI and automation to perform tasks that require human-level cognitive abilities, such as natural language understanding and problem-solving."
Compiler,A program that translates source code written in one programming language into another programming language or machine code.
Computer Vision,"A subset of AI that focuses on enabling machines to interpret and understand visual information from the world around them, including images and videos."
Constitutional AI,An AI training approach that uses a set of principles to guide model behavior through self-critique and revision.
Context Engineering,"The practice of architecting the complete information environment that shapes model behavior, including system prompts, conversation history, retrieved knowledge, and tool definitions."
Context Window,"The maximum amount of text (measured in tokens) that a language model can process in a single input, determining how much information it can consider at once."
Continual Learning,"A machine learning approach that involves learning from a continuous stream of data, enabling models to adapt and improve over time."
Convolutional Neural Networks (CNNs),"A type of neural network commonly used for computer vision tasks, such as image recognition and object detection."
Cross-Validation,A technique for assessing the performance of machine learning models by testing them on multiple subsets of the data.
Data Governance,"A set of processes and policies that ensure the proper management, protection, and utilization of an organization's data assets."
Data Imputation,The process of filling in missing or incomplete data with estimated values or imputed data.
Data Integration,"The process of combining data from multiple sources into a single, unified view."
Data Lake,"A storage repository that allows organizations to store large amounts of structured, semi-structured, and unstructured data at scale."
Data Mining,"The process of discovering patterns and insights from large amounts of data, typically using statistical and computational methods."
Data Pipeline,"A series of automated processes that extract, transform, and load data from various sources into a target system."
Data Profiling,"The process of analyzing and assessing the quality, completeness, and consistency of a dataset."
Data Quality,"The accuracy, completeness, consistency, and timeliness of data."
Data Stewardship,"The ongoing management and maintenance of data to ensure its accuracy, completeness, and consistency."
Data Wrangling,"The process of cleaning, transforming, and preparing raw data for analysis or modeling."
Debugging,The process of identifying and fixing errors or defects in computer programs.
Decision Trees,"A machine learning technique that involves building a tree-like model of decisions based on features and outcomes, often used for classification and regression tasks."
Deep Learning,"A subset of ML that uses neural networks to analyze large amounts of data, enabling machines to recognize patterns and make more accurate predictions."
Deep Reinforcement Learning,"A type of machine learning that combines deep learning and reinforcement learning, enabling models to learn from trial and error in complex environments."
Differentiable Programming,"The use of automatic differentiation to enable machine learning models to be used as building blocks for other models, enabling faster and more efficient model design."
Diffusion Model,"A generative model that learns to create data by gradually removing noise from random inputs, widely used for image generation."
Dimensionality Reduction,"The process of reducing the number of features or variables in a dataset, often used to simplify analysis or visualization, or to address the curse of dimensionality."
Edge AI,"The use of artificial intelligence algorithms and models on edge devices, such as smartphones, IoT devices, and drones, to enable real-time decision-making and reduce latency."
Embedding,"A numerical vector representation of data (text, images, etc.) that captures semantic meaning, enabling similarity comparisons and search."
Emergent Behavior,Capabilities that arise in large AI models that were not explicitly programmed or present in smaller versions of the same architecture.
Ensemble Learning,"A technique for combining multiple machine learning models to improve overall performance, often using methods such as bagging, boosting, or stacking."
Evolutionary Algorithms,"A family of optimization algorithms that are inspired by biological evolution, such as genetic algorithms and evolution strategies."
Expert System,A computer program that emulates the decision-making abilities of a human expert in a particular domain.
Explainability Gap,"The difference between the level of understanding humans have of a machine learning model and the actual decision-making process of the model, which can lead to mistrust and ethical concerns."
Explainable AI (XAI),"An approach to AI that aims to make machine learning models more transparent and interpretable, enabling humans to understand how decisions are made and identify potential biases."
Feature Extraction,The process of selecting or transforming input data into a form that is suitable for machine learning algorithms.
Federated Learning,A machine learning technique that enables multiple devices or servers to collaboratively train a model without sharing raw data with each other.
Few-Shot Learning,"A type of machine learning that involves training models to learn from a small number of examples, enabling faster and more efficient learning."
Fine-Tuning,The process of further training a pre-trained model on task-specific data to improve its performance on particular applications.
Foundation Model,A large AI model trained on broad data that can be adapted to a wide range of downstream tasks through fine-tuning or prompting.
Framework,A set of software components that provides a foundation for developing software applications in a specific programming language or environment.
Function,A reusable block of code that performs a specific task and can be called by other parts of the program.
Generative Adversarial Networks (GANs),"A type of deep learning model that involves two neural networks working together to generate new data, such as images or audio, that is similar to a given dataset."
GPT (Generative Pre-trained Transformer),"A family of large language models created by OpenAI, capable of generating natural language text, translating languages, and answering questions."
Gradient Boosting,"A machine learning technique that involves combining multiple weak models (usually decision trees) into a strong ensemble model, often used for regression and classification tasks."
Gradient Descent,A popular optimization algorithm used in machine learning to adjust the weights and biases of neural networks and other models.
Grounding,Techniques that anchor AI outputs to verified sources or real-world data to reduce hallucinations and improve factual accuracy.
Guardrails,"Safety mechanisms and constraints implemented to prevent AI models from generating harmful, biased, or inappropriate outputs."
Hallucination,When an AI model generates plausible-sounding but factually incorrect or fabricated information.
Human-in-the-Loop (HITL),"An approach to AI that involves human oversight and intervention to ensure that machine learning models are accurate, ethical, and aligned with human values."
Hyperautomation,"A digital transformation strategy that combines AI, machine learning, and other technologies to automate and optimize business processes."
Hyperparameter Tuning,The process of adjusting the settings or parameters of a machine learning algorithm to optimize its performance on a given task or dataset.
IDE (Integrated Development Environment),A software application that provides comprehensive facilities to computer programmers for software development.
In-Context Learning,"The ability of language models to learn and adapt to new tasks from examples provided within the prompt, without updating model weights."
Inference,The process of running a trained model to generate predictions or outputs from new input data.
Jailbreaking,Techniques used to bypass the safety guidelines and content restrictions of AI models to elicit prohibited outputs.
Knowledge Graphs,"A type of graph database that stores and represents knowledge in a structured format, enabling AI systems to reason and make inferences based on the data."
Large Language Model (LLM),"A neural network trained on massive text datasets that can understand and generate human-like text, typically with billions of parameters."
Latent Space,"A compressed, lower-dimensional representation of data learned by generative models, where similar concepts are positioned nearby."
Loop,A control structure that repeats a block of code until a certain condition is met.
LoRA (Low-Rank Adaptation),An efficient fine-tuning technique that reduces computational requirements by training only small adapter layers rather than all model parameters.
Machine Learning (ML),A subset of AI that uses statistical models and algorithms to enable machines to learn from data and make predictions or decisions without being explicitly programmed.
Meta-Learning,"A machine learning approach that involves learning how to learn, enabling models to generalize to new tasks and data more effectively."
Metadata,"Data that describes other data, including information about data sources, data lineage, data quality, and data relationships."
Mixture of Experts (MoE),A neural network architecture that uses multiple specialized sub-networks (experts) and a routing mechanism to efficiently scale model capacity.
Model Context Protocol (MCP),An open protocol that standardizes how AI applications connect to external data sources and tools.
Model Evaluation (Evals),"The systematic assessment of AI model performance using benchmarks, metrics, and human judgment to measure quality and safety."
Model Selection,"The process of choosing the most appropriate machine learning model for a given task or dataset, based on factors such as accuracy, complexity, and interpretability."
Module,A self-contained unit of code that can be reused and imported into other programs in computer programming.
Multi-Agent System,"An AI architecture where multiple specialized agents collaborate, communicate, and coordinate to solve complex problems."
Multi-Modal AI,"An AI system that can understand and process multiple forms of data, such as text, images, and audio, to make more accurate predictions or decisions."
Multi-Modal Learning,"A machine learning technique that involves processing multiple types of data simultaneously, such as text, images, and audio."
Natural Language Generation (NLG),A type of AI technology that enables machines to produce human-like language and generate written or spoken content.
Natural Language Processing (NLP),"The ability of machines to understand, interpret, and generate human language."
Neural Network,"A type of machine learning model inspired by the structure of the human brain, consisting of interconnected nodes that process and transmit information."
Neuromorphic Computing,"A type of computing that is inspired by the structure and function of biological neural networks, enabling the creation of more efficient and scalable AI systems."
Object,An instance of a class in object-oriented programming that encapsulates data and behavior.
One-Shot Learning,"A type of machine learning that involves learning from a single or few examples, often used to address the data scarcity problem."
Orchestration,"The coordination and management of multiple AI agents, tools, or model calls to accomplish complex multi-step tasks."
Overfitting,"When a machine learning model is overly complex and fits the training data too closely, leading to poor performance on new, unseen data."
Pointer,A variable that holds the memory address of another variable in computer programming.
Predictive Analytics,The use of statistical models and machine learning algorithms to make predictions or forecasts about future events based on historical data.
Principal Component Analysis (PCA),A dimensionality reduction technique that involves transforming a dataset into a lower-dimensional space while preserving the most important information.
Prompt Engineering,"The process of designing, refining, and optimizing natural language prompts to elicit desired responses from language models."
Prompt Injection,A security vulnerability where malicious inputs manipulate a language model into ignoring its instructions or performing unintended actions.
Prompt Tuning,The process of adjusting and fine-tuning prompts to improve the performance of language models on specific tasks.
Quantization,A model compression technique that reduces the precision of model weights to decrease memory usage and increase inference speed.
Quantum Machine Intelligence,"The integration of quantum computing and machine learning, enabling the creation of more efficient and accurate AI systems."
Quantum Machine Learning,"The use of quantum computing to accelerate machine learning tasks, such as optimization and pattern recognition, enabling faster and more efficient learning."
Quantum Neural Networks (QNNs),"A type of neural network designed to run on quantum computing architectures, enabling faster and more efficient processing of complex data."
Random Forest,A machine learning technique that involves constructing multiple decision trees and combining their predictions to improve the accuracy and stability of a model.
Red Teaming,A systematic approach to testing AI systems by simulating adversarial attacks to identify vulnerabilities and failure modes.
Regularization,"A technique for preventing overfitting in machine learning by adding a penalty term to the model that encourages simpler, more generalizable solutions."
Reinforcement Learning,A type of machine learning in which an agent learns to interact with an environment by performing actions and receiving rewards or punishments based on those actions.
Responsible AI,"The development and deployment of AI systems that are transparent, accountable, and designed to minimize negative impacts on society and the environment."
Retrieval-Augmented Generation (RAG),A technique that enhances language model outputs by retrieving relevant information from external knowledge sources and including it in the context.
RLHF (Reinforcement Learning from Human Feedback),"A training technique that uses human preferences to guide model behavior, helping align outputs with human values and expectations."
Robotics,"The field of engineering that involves designing and building robots that can perform a variety of tasks, ranging from manufacturing and assembly to exploration and rescue operations."
Self-Supervised Learning,"A machine learning approach that enables models to learn from unlabeled data, reducing the need for human-labeled datasets."
Semantic Search,A search technique that uses embeddings to find results based on meaning and intent rather than exact keyword matches.
Speech Recognition,The ability of machines to recognize and transcribe spoken language into text.
Supervised Learning,"A type of machine learning where the algorithm learns from labeled training data, and makes predictions or decisions based on that learning."
Swarm Intelligence,"A collective intelligence approach inspired by social behavior in insects and animals, used to optimize decision-making in complex systems."
Synthetic Biology,"The design and engineering of biological systems using synthetic DNA, enabling the creation of new organisms and materials with specific functions."
Synthetic Data,"Artificially generated data that is designed to mimic real-world data, used for training and testing machine learning models while preserving data privacy."
Synthetic Media,"AI-generated media, such as images, videos, and audio, that can be used for entertainment, marketing, or other applications."
System Prompt,"Instructions provided to a language model that define its behavior, persona, capabilities, and constraints across an entire conversation."
Temperature,"A parameter that controls the randomness of model outputs, where higher values produce more creative responses and lower values produce more deterministic ones."
Time Series Analysis,"A type of analysis that involves modeling and forecasting data that is indexed by time, such as stock prices, weather patterns, or website traffic."
Token,"The basic unit of text processed by language models, which can be a word, subword, or character depending on the tokenization method."
Tool Use / Function Calling,"The capability of language models to invoke external tools, APIs, or functions to extend their abilities beyond text generation."
Transfer Learning,"A machine learning approach that involves reusing pre-trained models and transferring knowledge to new domains or tasks, enabling faster and more efficient learning."
Transformer,"A type of neural network architecture that uses attention mechanisms to process input sequences, and has achieved state-of-the-art results in natural language processing."
Underfitting,"When a machine learning model is too simple and fails to capture the underlying patterns in the data, leading to poor performance on both training and new data."
Unsupervised Learning,A type of machine learning in which the model is trained on unlabeled data and must identify patterns and structures on its own.
Variable,A named container that holds a value or reference to a value in computer programming.
Variational Autoencoder (VAE),"An extension of the autoencoder architecture that learns a probability distribution over the compressed representations of input data, allowing for the generation of new, similar data points."
Vector Database,"A specialized database designed to store, index, and query high-dimensional embedding vectors for fast similarity search."
Zero-Shot Learning,"The ability of a model to perform a task without any task-specific examples, relying solely on instructions and pre-trained knowledge."